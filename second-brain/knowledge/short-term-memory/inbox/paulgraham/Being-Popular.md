---
title: "Being Popular"
author: Paul Graham
source: http://paulgraham.com/popular.html
year_published: Unknown
date_scraped: 2025-08-07
time_scraped: 12:14:59
word_count: 7022
scrape_method: firecrawl
tags: [paul-graham, essays, startups, programming, philosophy]
---

# Being Popular

|     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- |
| ![](https://s.turbifycdn.com/aah/paulgraham/essays-5.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | [![](https://s.turbifycdn.com/aah/paulgraham/essays-6.gif)](https://paulgraham.com/index.html)

|     |
| --- |
| ![Being Popular](https://s.turbifycdn.com/aah/paulgraham/being-popular-2.gif)<br>May 2001<br>_(This article was written as a kind of business plan for a_<br>_[new language](https://paulgraham.com/arc.html)._<br>_So it is missing (because it takes for granted) the most important_<br>_feature of a good programming language: very powerful abstractions.)_<br>A friend of mine once told an eminent operating systems<br>expert that he wanted to design a really good<br>programming language. The expert told him that it would be a<br>waste of time, that programming languages don't become popular<br>or unpopular based on their merits, and so no matter how<br>good his language was, no one would use it. At least, that<br>was what had happened to the language _he_ had designed.<br>What does make a language popular? Do popular<br>languages deserve their popularity? Is it worth trying to<br>define a good programming language? How would you do it?<br>I think the answers to these questions can be found by looking <br>at hackers, and learning what they want. Programming<br>languages are _for_ hackers, and a programming language<br>is good as a programming language (rather than, say, an<br>exercise in denotational semantics or compiler design)<br>if and only if hackers like it.<br>**1 The Mechanics of Popularity**<br>It's true, certainly, that most people don't choose programming<br>languages simply based on their merits. Most programmers are told<br>what language to use by someone else. And yet I think the effect<br>of such external factors on the popularity of programming languages<br>is not as great as it's sometimes thought to be. I think a bigger<br>problem is that a hacker's idea of a good programming language is<br>not the same as most language designers'.<br>Between the two, the hacker's opinion is the one that matters.<br>Programming languages are not theorems. They're tools, designed<br>for people, and they have to be designed to suit human strengths<br>and weaknesses as much as shoes have to be designed for human feet.<br>If a shoe pinches when you put it on, it's a bad shoe, however<br>elegant it may be as a piece of sculpture.<br>It may be that the majority of programmers can't tell a good language<br>from a bad one. But that's no different with any other tool. It<br>doesn't mean that it's a waste of time to try designing a good<br>language. [Expert hackers](https://paulgraham.com/design.html) <br>can tell a good language when they see<br>one, and they'll use it. Expert hackers are a tiny minority,<br>admittedly, but that tiny minority write all the good software,<br>and their influence is such that the rest of the programmers will<br>tend to use whatever language they use. Often, indeed, it is not<br>merely influence but command: often the expert hackers are the very<br>people who, as their bosses or faculty advisors, tell the other<br>programmers what language to use.<br>The opinion of expert hackers is not the only force that determines<br>the relative popularity of programming languages — legacy software<br>(Cobol) and hype (Ada, Java) also play a role — but I think it is<br>the most powerful force over the long term. Given an initial critical<br>mass and enough time, a programming language probably becomes about<br>as popular as it deserves to be. And popularity further separates<br>good languages from bad ones, because feedback from real live users<br>always leads to improvements. Look at how much any popular language<br>has changed during its life. Perl and Fortran are extreme cases,<br>but even Lisp has changed a lot. Lisp 1.5 didn't have macros, for<br>example; these evolved later, after hackers at MIT had spent a<br>couple years using Lisp to write real programs. \[1\]<br>So whether or not a language has to be good to be popular, I think<br>a language has to be popular to be good. And it has to stay popular<br>to stay good. The state of the art in programming languages doesn't<br>stand still. And yet the Lisps we have today are still pretty much<br>what they had at MIT in the mid-1980s, because that's the last time<br>Lisp had a sufficiently large and demanding user base.<br>Of course, hackers have to know about a language before they can<br>use it. How are they to hear? From other hackers. But there has to<br>be some initial group of hackers using the language for others even<br>to hear about it. I wonder how large this group has to be; how many<br>users make a critical mass? Off the top of my head, I'd say twenty.<br>If a language had twenty separate users, meaning twenty users who<br>decided on their own to use it, I'd consider it to be real.<br>Getting there can't be easy. I would not be surprised if it is<br>harder to get from zero to twenty than from twenty to a thousand.<br>The best way to get those initial twenty users is probably to use<br>a trojan horse: to give people an application they want, which<br>happens to be written in the new language.<br>**2 External Factors**<br>Let's start by acknowledging one external factor that does affect<br>the popularity of a programming language. To become popular, a<br>programming language has to be the scripting language of a popular<br>system. Fortran and Cobol were the scripting languages of early<br>IBM mainframes. C was the scripting language of Unix, and so, later,<br>was Perl. Tcl is the scripting language of Tk. Java and Javascript<br>are intended to be the scripting languages of web browsers.<br>Lisp is not a massively popular language because it is not the<br>scripting language of a massively popular system. What popularity<br>it retains dates back to the 1960s and 1970s, when it was the<br>scripting language of MIT. A lot of the great programmers of the<br>day were associated with MIT at some point. And in the early 1970s,<br>before C, MIT's dialect of Lisp, called MacLisp, was one of the<br>only programming languages a serious hacker would want to use.<br>Today Lisp is the scripting language of two moderately popular<br>systems, Emacs and Autocad, and for that reason I suspect that most<br>of the Lisp programming done today is done in Emacs Lisp or AutoLisp.<br>Programming languages don't exist in isolation. To hack is a<br>transitive verb — hackers are usually hacking something — and in<br>practice languages are judged relative to whatever they're used to<br>hack. So if you want to design a popular language, you either have<br>to supply more than a language, or you have to design your language<br>to replace the scripting language of some existing system.<br>Common Lisp is unpopular partly because it's an orphan. It did<br>originally come with a system to hack: the Lisp Machine. But Lisp<br>Machines (along with parallel computers) were steamrollered by the<br>increasing power of general purpose processors in the 1980s. Common<br>Lisp might have remained popular if it had been a good scripting<br>language for Unix. It is, alas, an atrociously bad one.<br>One way to describe this situation is to say that a language isn't<br>judged on its own merits. Another view is that a programming language<br>really isn't a programming language unless it's also the scripting<br>language of something. This only seems unfair if it comes as a<br>surprise. I think it's no more unfair than expecting a programming<br>language to have, say, an implementation. It's just part of what<br>a programming language is.<br>A programming language does need a good implementation, of course,<br>and this must be free. Companies will pay for software, but individual<br>hackers won't, and it's the hackers you need to attract.<br>A language also needs to have a book about it. The book should be<br>thin, well-written, and full of good examples. K&R is the ideal<br>here. At the moment I'd almost say that a language has to have a<br>book published by O'Reilly. That's becoming the test of mattering<br>to hackers.<br>There should be online documentation as well. In fact, the book<br>can start as online documentation. But I don't think that physical<br>books are outmoded yet. Their format is convenient, and the de<br>facto censorship imposed by publishers is a useful if imperfect<br>filter. Bookstores are one of the most important places for learning<br>about new languages.<br>**3 Brevity**<br>Given that you can supply the three things any language needs — a<br>free implementation, a book, and something to hack — how do you<br>make a language that hackers will like?<br>One thing hackers like is brevity. Hackers are lazy, in the same<br>way that mathematicians and modernist architects are lazy: they<br>hate anything extraneous. It would not be far from the truth to<br>say that a hacker about to write a program decides what language<br>to use, at least subconsciously, based on the total number of<br>characters he'll have to type. If this isn't precisely how hackers<br>think, a language designer would do well to act as if it were.<br>It is a mistake to try to baby the user with long-winded expressions<br>that are meant to resemble English. Cobol is notorious for this<br>flaw. A hacker would consider being asked to write<br>add x to y giving z<br>instead of<br>z = x+y<br>as something between an insult to his intelligence and a sin against<br>God.<br>It has sometimes been said that Lisp should use first and rest<br>instead of car and cdr, because it would make programs easier to<br>read. Maybe for the first couple hours. But a hacker can learn<br>quickly enough that car means the first element of a list and cdr<br>means the rest. Using first and rest means 50% more typing. And<br>they are also different lengths, meaning that the arguments won't<br>line up when they're called, as car and cdr often are, in successive<br>lines. I've found that it matters a lot how code lines up on the<br>page. I can barely read Lisp code when it is set in a variable-width<br>font, and friends say this is true for other languages too.<br>Brevity is one place where strongly typed languages lose. All other<br>things being equal, no one wants to begin a program with a bunch<br>of declarations. Anything that can be implicit, should be.<br>The individual tokens should be short as well. Perl and Common Lisp<br>occupy opposite poles on this question. Perl programs can be almost<br>cryptically dense, while the names of built-in Common Lisp operators<br>are comically long. The designers of Common Lisp probably expected<br>users to have text editors that would type these long names for<br>them. But the cost of a long name is not just the cost of typing<br>it. There is also the cost of reading it, and the cost of the space<br>it takes up on your screen.<br>**4 Hackability**<br>There is one thing more important than brevity to a hacker: being<br>able to do what you want. In the history of programming languages<br>a surprising amount of effort has gone into preventing programmers<br>from doing things considered to be improper. This is a dangerously<br>presumptuous plan. How can the language designer know what the<br>programmer is going to need to do? I think language designers would<br>do better to consider their target user to be a genius who will<br>need to do things they never anticipated, rather than a bumbler<br>who needs to be protected from himself. The bumbler will shoot<br>himself in the foot anyway. You may save him from referring to<br>variables in another package, but you can't save him from writing<br>a badly designed program to solve the wrong problem, and taking<br>forever to do it.<br>Good programmers often want to do dangerous and unsavory things.<br>By unsavory I mean things that go behind whatever semantic facade<br>the language is trying to present: getting hold of the internal<br>representation of some high-level abstraction, for example. Hackers<br>like to hack, and hacking means getting inside things and second<br>guessing the original designer.<br>_Let yourself be second guessed._ When you make any tool, people use<br>it in ways you didn't intend, and this is especially true of a<br>highly articulated tool like a programming language. Many a hacker<br>will want to tweak your semantic model in a way that you never<br>imagined. I say, let them; give the programmer access to as much<br>internal stuff as you can without endangering runtime systems like<br>the garbage collector.<br>In Common Lisp I have often wanted to iterate through the fields<br>of a struct — to comb out references to a deleted object, for example,<br>or find fields that are uninitialized. I know the structs are just<br>vectors underneath. And yet I can't write a general purpose function<br>that I can call on any struct. I can only access the fields by<br>name, because that's what a struct is supposed to mean.<br>A hacker may only want to subvert the intended model of things once<br>or twice in a big program. But what a difference it makes to be<br>able to. And it may be more than a question of just solving a<br>problem. There is a kind of pleasure here too. Hackers share the<br>surgeon's secret pleasure in poking about in gross innards, the<br>teenager's secret pleasure in popping zits. \[2\] For boys, at least,<br>certain kinds of horrors are fascinating. Maxim magazine publishes<br>an annual volume of photographs, containing a mix of pin-ups and<br>grisly accidents. They know their audience.<br>Historically, Lisp has been good at letting hackers have their way.<br>The political correctness of Common Lisp is an aberration. Early<br>Lisps let you get your hands on everything. A good deal of that<br>spirit is, fortunately, preserved in macros. What a wonderful thing,<br>to be able to make arbitrary transformations on the source code.<br>Classic macros are a real hacker's tool — simple, powerful, and<br>dangerous. It's so easy to understand what they do: you call a<br>function on the macro's arguments, and whatever it returns gets<br>inserted in place of the macro call. Hygienic macros embody the<br>opposite principle. They try to protect you from understanding what<br>they're doing. I have never heard hygienic macros explained in one<br>sentence. And they are a classic example of the dangers of deciding<br>what programmers are allowed to want. Hygienic macros are intended<br>to protect me from variable capture, among other things, but variable<br>capture is exactly what I want in some macros.<br>A really good language should be both clean and dirty: cleanly<br>designed, with a small core of well understood and highly orthogonal<br>operators, but dirty in the sense that it lets hackers have their<br>way with it. C is like this. So were the early Lisps. A real hacker's<br>language will always have a slightly raffish character.<br>A good programming language should have features that make the kind<br>of people who use the phrase "software engineering" shake their<br>heads disapprovingly. At the other end of the continuum are languages<br>like Ada and Pascal, models of propriety that are good for teaching<br>and not much else.<br>**5 Throwaway Programs**<br>To be attractive to hackers, a language must be good for writing<br>the kinds of programs they want to write. And that means, perhaps<br>surprisingly, that it has to be good for writing throwaway programs.<br>A throwaway program is a program you write quickly for some limited<br>task: a program to automate some system administration task, or<br>generate test data for a simulation, or convert data from one format<br>to another. The surprising thing about throwaway programs is that,<br>like the "temporary" buildings built at so many American universities<br>during World War II, they often don't get thrown away. Many evolve<br>into real programs, with real features and real users.<br>I have a hunch that the best big programs begin life this way,<br>rather than being designed big from the start, like the Hoover Dam.<br>It's terrifying to build something big from scratch. When people<br>take on a project that's too big, they become overwhelmed. The<br>project either gets bogged down, or the result is sterile and<br>wooden: a shopping mall rather than a real downtown, Brasilia rather<br>than Rome, Ada rather than C.<br>Another way to get a big program is to start with a throwaway<br>program and keep improving it. This approach is less daunting, and<br>the design of the program benefits from evolution. I think, if one<br>looked, that this would turn out to be the way most big programs<br>were developed. And those that did evolve this way are probably<br>still written in whatever language they were first written in,<br>because it's rare for a program to be ported, except for political<br>reasons. And so, paradoxically, if you want to make a language that<br>is used for big systems, you have to make it good for writing<br>throwaway programs, because that's where big systems come from.<br>Perl is a striking example of this idea. It was not only designed<br>for writing throwaway programs, but was pretty much a throwaway<br>program itself. Perl began life as a collection of utilities for<br>generating reports, and only evolved into a programming language<br>as the throwaway programs people wrote in it grew larger. It was<br>not until Perl 5 (if then) that the language was suitable for<br>writing serious programs, and yet it was already massively popular.<br>What makes a language good for throwaway programs? To start with,<br>it must be readily available. A throwaway program is something that<br>you expect to write in an hour. So the language probably must<br>already be installed on the computer you're using. It can't be<br>something you have to install before you use it. It has to be there.<br>C was there because it came with the operating system. Perl was<br>there because it was originally a tool for system administrators,<br>and yours had already installed it.<br>Being available means more than being installed, though. An<br>interactive language, with a command-line interface, is more<br>available than one that you have to compile and run separately. A<br>popular programming language should be interactive, and start up<br>fast.<br>Another thing you want in a throwaway program is brevity. Brevity<br>is always attractive to hackers, and never more so than in a program<br>they expect to turn out in an hour.<br>**6 Libraries**<br>Of course the ultimate in brevity is to have the program already<br>written for you, and merely to call it. And this brings us to what<br>I think will be an increasingly important feature of programming<br>languages: library functions. Perl wins because it has large<br>libraries for manipulating strings. This class of library functions<br>are especially important for throwaway programs, which are often<br>originally written for converting or extracting data. Many Perl<br>programs probably begin as just a couple library calls stuck<br>together.<br>I think a lot of the advances that happen in programming languages<br>in the next fifty years will have to do with library functions. I<br>think future programming languages will have libraries that are as<br>carefully designed as the core language. Programming language design<br>will not be about whether to make your language strongly or weakly<br>typed, or object oriented, or functional, or whatever, but about<br>how to design great libraries. The kind of language designers who<br>like to think about how to design type systems may shudder at this.<br>It's almost like writing applications! Too bad. Languages are for<br>programmers, and libraries are what programmers need.<br>It's hard to design good libraries. It's not simply a matter of<br>writing a lot of code. Once the libraries get too big, it can<br>sometimes take longer to find the function you need than to write<br>the code yourself. Libraries need to be designed using a small set<br>of orthogonal operators, just like the core language. It ought to<br>be possible for the programmer to guess what library call will do<br>what he needs.<br>Libraries are one place Common Lisp falls short. There are only<br>rudimentary libraries for manipulating strings, and almost none<br>for talking to the operating system. For historical reasons, Common<br>Lisp tries to pretend that the OS doesn't exist. And because you<br>can't talk to the OS, you're unlikely to be able to write a serious<br>program using only the built-in operators in Common Lisp. You have<br>to use some implementation-specific hacks as well, and in practice<br>these tend not to give you everything you want. Hackers would think<br>a lot more highly of Lisp if Common Lisp had powerful string<br>libraries and good OS support.<br>**7 Syntax**<br>Could a language with Lisp's syntax, or more precisely, lack of<br>syntax, ever become popular? I don't know the answer to this<br>question. I do think that syntax is not the main reason Lisp isn't<br>currently popular. Common Lisp has worse problems than unfamiliar<br>syntax. I know several programmers who are comfortable with prefix<br>syntax and yet use Perl by default, because it has powerful string<br>libraries and can talk to the os.<br>There are two possible problems with prefix notation: that it is<br>unfamiliar to programmers, and that it is not dense enough. The<br>conventional wisdom in the Lisp world is that the first problem is<br>the real one. I'm not so sure. Yes, prefix notation makes ordinary<br>programmers panic. But I don't think ordinary programmers' opinions<br>matter. Languages become popular or unpopular based on what expert<br>hackers think of them, and I think expert hackers might be able to<br>deal with prefix notation. Perl syntax can be pretty incomprehensible,<br>but that has not stood in the way of Perl's popularity. If anything<br>it may have helped foster a Perl cult.<br>A more serious problem is the diffuseness of prefix notation. For<br>expert hackers, that really is a problem. No one wants to write<br>(aref a x y) when they could write a\[x,y\].<br>In this particular case there is a way to finesse our way out of<br>the problem. If we treat data structures as if they were functions<br>on indexes, we could write (a x y) instead, which is even shorter<br>than the Perl form. Similar tricks may shorten other types of<br>expressions.<br>We can get rid of (or make optional) a lot of parentheses by making<br>indentation significant. That's how programmers read code anyway:<br>when indentation says one thing and delimiters say another, we go<br>by the indentation. Treating indentation as significant would<br>eliminate this common source of bugs as well as making programs<br>shorter.<br>Sometimes infix syntax is easier to read. This is especially true<br>for math expressions. I've used Lisp my whole programming life and<br>I still don't find prefix math expressions natural. And yet it is<br>convenient, especially when you're generating code, to have operators<br>that take any number of arguments. So if we do have infix syntax,<br>it should probably be implemented as some kind of read-macro.<br>I don't think we should be religiously opposed to introducing syntax<br>into Lisp, as long as it translates in a well-understood way into<br>underlying s-expressions. There is already a good deal of syntax<br>in Lisp. It's not necessarily bad to introduce more, as long as no<br>one is forced to use it. In Common Lisp, some delimiters are reserved<br>for the language, suggesting that at least some of the designers<br>intended to have more syntax in the future.<br>One of the most egregiously unlispy pieces of syntax in Common Lisp<br>occurs in format strings; format is a language in its own right,<br>and that language is not Lisp. If there were a plan for introducing<br>more syntax into Lisp, format specifiers might be able to be included<br>in it. It would be a good thing if macros could generate format<br>specifiers the way they generate any other kind of code.<br>An eminent Lisp hacker told me that his copy of CLTL falls open to<br>the section format. Mine too. This probably indicates room for<br>improvement. It may also mean that programs do a lot of I/O.<br>**8 Efficiency**<br>A good language, as everyone knows, should generate fast code. But<br>in practice I don't think fast code comes primarily from things<br>you do in the design of the language. As Knuth pointed out long<br>ago, speed only matters in certain critical bottlenecks. And as<br>many programmers have observed since, one is very often mistaken<br>about where these bottlenecks are.<br>So, in practice, the way to get fast code is to have a very good<br>profiler, rather than by, say, making the language strongly typed.<br>You don't need to know the type of every argument in every call in<br>the program. You do need to be able to declare the types of arguments<br>in the bottlenecks. And even more, you need to be able to find out<br>where the bottlenecks are.<br>One complaint people have had with Lisp is that it's hard to tell<br>what's expensive. This might be true. It might also be inevitable,<br>if you want to have a very abstract language. And in any case I<br>think good profiling would go a long way toward fixing the problem:<br>you'd soon learn what was expensive.<br>Part of the problem here is social. Language designers like to<br>write fast compilers. That's how they measure their skill. They<br>think of the profiler as an add-on, at best. But in practice a good<br>profiler may do more to improve the speed of actual programs written<br>in the language than a compiler that generates fast code. Here,<br>again, language designers are somewhat out of touch with their<br>users. They do a really good job of solving slightly the wrong<br>problem.<br>It might be a good idea to have an active profiler — to push<br>performance data to the programmer instead of waiting for him to<br>come asking for it. For example, the editor could display bottlenecks<br>in red when the programmer edits the source code. Another approach<br>would be to somehow represent what's happening in running programs.<br>This would be an especially big win in server-based applications,<br>where you have lots of running programs to look at. An active<br>profiler could show graphically what's happening in memory as a<br>program's running, or even make sounds that tell what's happening.<br>Sound is a good cue to problems. In one place I worked, we had a<br>big board of dials showing what was happening to our web servers.<br>The hands were moved by little servomotors that made a slight noise<br>when they turned. I couldn't see the board from my desk, but I<br>found that I could tell immediately, by the sound, when there was<br>a problem with a server.<br>It might even be possible to write a profiler that would automatically<br>detect inefficient algorithms. I would not be surprised if certain<br>patterns of memory access turned out to be sure signs of bad<br>algorithms. If there were a little guy running around inside the<br>computer executing our programs, he would probably have as long<br>and plaintive a tale to tell about his job as a federal government<br>employee. I often have a feeling that I'm sending the processor on<br>a lot of wild goose chases, but I've never had a good way to look<br>at what it's doing.<br>A number of Lisps now compile into byte code, which is then executed<br>by an interpreter. This is usually done to make the implementation<br>easier to port, but it could be a useful language feature. It might<br>be a good idea to make the byte code an official part of the<br>language, and to allow programmers to use inline byte code in<br>bottlenecks. Then such optimizations would be portable too.<br>The nature of speed, as perceived by the end-user, may be changing.<br>With the rise of server-based applications, more and more programs<br>may turn out to be i/o-bound. It will be worth making i/o fast.<br>The language can help with straightforward measures like simple,<br>fast, formatted output functions, and also with deep structural<br>changes like caching and persistent objects.<br>Users are interested in response time. But another kind of efficiency<br>will be increasingly important: the number of simultaneous users<br>you can support per processor. Many of the interesting applications<br>written in the near future will be server-based, and the number of<br>users per server is the critical question for anyone hosting such<br>applications. In the capital cost of a business offering a server-based<br>application, this is the divisor.<br>For years, efficiency hasn't mattered much in most end-user<br>applications. Developers have been able to assume that each user<br>would have an increasingly powerful processor sitting on their<br>desk. And by Parkinson's Law, software has expanded to use the<br>resources available. That will change with server-based applications.<br>In that world, the hardware and software will be supplied together.<br>For companies that offer server-based applications, it will make<br>a very big difference to the bottom line how many users they can<br>support per server.<br>In some applications, the processor will be the limiting factor,<br>and execution speed will be the most important thing to optimize.<br>But often memory will be the limit; the number of simultaneous<br>users will be determined by the amount of memory you need for each<br>user's data. The language can help here too. Good support for<br>threads will enable all the users to share a single heap. It may<br>also help to have persistent objects and/or language level support<br>for lazy loading.<br>**9 Time**<br>The last ingredient a popular language needs is time. No one wants<br>to write programs in a language that might go away, as so many<br>programming languages do. So most hackers will tend to wait until<br>a language has been around for a couple years before even considering<br>using it.<br>Inventors of wonderful new things are often surprised to discover<br>this, but you need time to get any message through to people. A<br>friend of mine rarely does anything the first time someone asks<br>him. He knows that people sometimes ask for things that they turn<br>out not to want. To avoid wasting his time, he waits till the third<br>or fourth time he's asked to do something; by then, whoever's asking<br>him may be fairly annoyed, but at least they probably really do<br>want whatever they're asking for.<br>Most people have learned to do a similar sort of filtering on new<br>things they hear about. They don't even start paying attention<br>until they've heard about something ten times. They're perfectly<br>justified: the majority of hot new whatevers do turn out to be a<br>waste of time, and eventually go away. By delaying learning VRML,<br>I avoided having to learn it at all.<br>So anyone who invents something new has to expect to keep repeating<br>their message for years before people will start to get it. We<br>wrote what was, as far as I know, the first web-server based<br>application, and it took us years to get it through to people that<br>it didn't have to be downloaded. It wasn't that they were stupid.<br>They just had us tuned out.<br>The good news is, simple repetition solves the problem. All you<br>have to do is keep telling your story, and eventually people will<br>start to hear. It's not when people notice you're there that they<br>pay attention; it's when they notice you're still there.<br>It's just as well that it usually takes a while to gain momentum.<br>Most technologies evolve a good deal even after they're first<br>launched — programming languages especially. Nothing could be better,<br>for a new techology, than a few years of being used only by a small<br>number of early adopters. Early adopters are sophisticated and<br>demanding, and quickly flush out whatever flaws remain in your<br>technology. When you only have a few users you can be in close<br>contact with all of them. And early adopters are forgiving when<br>you improve your system, even if this causes some breakage.<br>There are two ways new technology gets introduced: the organic<br>growth method, and the big bang method. The organic growth method<br>is exemplified by the classic seat-of-the-pants underfunded garage<br>startup. A couple guys, working in obscurity, develop some new<br>technology. They launch it with no marketing and initially have<br>only a few (fanatically devoted) users. They continue to improve<br>the technology, and meanwhile their user base grows by word of<br>mouth. Before they know it, they're big.<br>The other approach, the big bang method, is exemplified by the<br>VC-backed, heavily marketed startup. They rush to develop a product,<br>launch it with great publicity, and immediately (they hope) have<br>a large user base.<br>Generally, the garage guys envy the big bang guys. The big bang<br>guys are smooth and confident and respected by the VCs. They can<br>afford the best of everything, and the PR campaign surrounding the<br>launch has the side effect of making them celebrities. The organic<br>growth guys, sitting in their garage, feel poor and unloved. And<br>yet I think they are often mistaken to feel sorry for themselves.<br>Organic growth seems to yield better technology and richer founders<br>than the big bang method. If you look at the dominant technologies<br>today, you'll find that most of them grew organically.<br>This pattern doesn't only apply to companies. You see it in sponsored<br>research too. Multics and Common Lisp were big-bang projects, and<br>Unix and MacLisp were organic growth projects.<br>**10 Redesign**<br>"The best writing is rewriting," wrote E. B. White. Every good<br>writer knows this, and it's true for software too. The most important<br>part of design is redesign. Programming languages, especially,<br>don't get redesigned enough.<br>To write good software you must simultaneously keep two opposing<br>ideas in your head. You need the young hacker's naive faith in<br>his abilities, and at the same time the veteran's skepticism. You<br>have to be able to think <br>[how hard can it be?](http://www.trevorblackwell.com/) with one half of<br>your brain while thinking <br>[it will never work](http://www.pdos.lcs.mit.edu/~rtm/) with the other.<br>The trick is to realize that there's no real contradiction here.<br>You want to be optimistic and skeptical about two different things.<br>You have to be optimistic about the possibility of solving the<br>problem, but skeptical about the value of whatever solution you've<br>got so far.<br>People who do good work often think that whatever they're working<br>on is no good. Others see what they've done and are full of wonder,<br>but the creator is full of worry. This pattern is no coincidence:<br>it is the worry that made the work good.<br>If you can keep hope and worry balanced, they will drive a project<br>forward the same way your two legs drive a bicycle forward. In the<br>first phase of the two-cycle innovation engine, you work furiously<br>on some problem, inspired by your confidence that you'll be able<br>to solve it. In the second phase, you look at what you've done in<br>the cold light of morning, and see all its flaws very clearly. But<br>as long as your critical spirit doesn't outweigh your hope, you'll<br>be able to look at your admittedly incomplete system, and think,<br>how hard can it be to get the rest of the way?, thereby continuing<br>the cycle.<br>It's tricky to keep the two forces balanced. In young hackers,<br>optimism predominates. They produce something, are convinced it's<br>great, and never improve it. In old hackers, skepticism predominates,<br>and they won't even dare to take on ambitious projects.<br>Anything you can do to keep the redesign cycle going is good. Prose<br>can be rewritten over and over until you're happy with it. But<br>software, as a rule, doesn't get redesigned enough. Prose has<br>readers, but software has _users._ If a writer rewrites an essay,<br>people who read the old version are unlikely to complain that their<br>thoughts have been broken by some newly introduced incompatibility.<br>Users are a double-edged sword. They can help you improve your<br>language, but they can also deter you from improving it. So choose<br>your users carefully, and be slow to grow their number. Having<br>users is like optimization: the wise course is to delay it. Also,<br>as a general rule, you can at any given time get away with changing<br>more than you think. Introducing change is like pulling off a<br>bandage: the pain is a memory almost as soon as you feel it.<br>Everyone knows that it's not a good idea to have a language designed<br>by a committee. Committees yield bad design. But I think the worst<br>danger of committees is that they interfere with redesign. It is<br>so much work to introduce changes that no one wants to bother.<br>Whatever a committee decides tends to stay that way, even if most<br>of the members don't like it.<br>Even a committee of two gets in the way of redesign. This happens<br>particularly in the interfaces between pieces of software written<br>by two different people. To change the interface both have to agree<br>to change it at once. And so interfaces tend not to change at all,<br>which is a problem because they tend to be one of the most ad hoc<br>parts of any system.<br>One solution here might be to design systems so that interfaces<br>are horizontal instead of vertical — so that modules are always<br>vertically stacked strata of abstraction. Then the interface will<br>tend to be owned by one of them. The lower of two levels will either<br>be a language in which the upper is written, in which case the<br>lower level will own the interface, or it will be a slave, in which<br>case the interface can be dictated by the upper level.<br>**11 Lisp**<br>What all this implies is that there is hope for a new Lisp. There<br>is hope for any language that gives hackers what they want, including<br>Lisp. I think we may have made a mistake in thinking that hackers<br>are turned off by Lisp's strangeness. This comforting illusion may<br>have prevented us from seeing the real problem with Lisp, or at<br>least Common Lisp, which is that it sucks for doing what hackers<br>want to do. A hacker's language needs powerful libraries and<br>something to hack. Common Lisp has neither. A hacker's language is<br>terse and hackable. Common Lisp is not.<br>The good news is, it's not Lisp that sucks, but Common Lisp. If we<br>can develop a new Lisp that is a real hacker's language, I think<br>hackers will use it. They will use whatever language does the job.<br>All we have to do is make sure this new Lisp does some important<br>job better than other languages.<br>History offers some encouragement. Over time, successive new<br>programming languages have taken more and more features from Lisp.<br>There is no longer much left to copy before the language you've<br>made is Lisp. The latest hot language, Python, is a watered-down<br>Lisp with infix syntax and no macros. A new Lisp would be a natural<br>step in this progression.<br>I sometimes think that it would be a good marketing trick to call<br>it an improved version of Python. That sounds hipper than Lisp. To<br>many people, Lisp is a slow AI language with a lot of parentheses.<br>Fritz Kunze's official biography carefully avoids mentioning the<br>L-word. But my guess is that we shouldn't be afraid to call the<br>new Lisp Lisp. Lisp still has a lot of latent respect among the<br>very best hackers — the ones who took 6.001 and understood it, for<br>example. And those are the users you need to win.<br>In "How to Become a Hacker," Eric Raymond describes Lisp as something<br>like Latin or Greek — a language you should learn as an intellectual<br>exercise, even though you won't actually use it:<br>> Lisp is worth learning for the profound enlightenment experience<br>>  you will have when you finally get it; that experience will make<br>>  you a better programmer for the rest of your days, even if you<br>>  never actually use Lisp itself a lot.<br>If I didn't know Lisp, reading this would set me asking questions.<br>A language that would make me a better programmer, if it means<br>anything at all, means a language that would be better for programming.<br>And that is in fact the implication of what Eric is saying.<br>As long as that idea is still floating around, I think hackers will<br>be receptive enough to a new Lisp, even if it is called Lisp. But<br>this Lisp must be a hacker's language, like the classic Lisps of<br>the 1970s. It must be terse, simple, and hackable. And it must have<br>powerful libraries for doing what hackers want to do now.<br>In the matter of libraries I think there is room to beat languages<br>like Perl and Python at their own game. A lot of the new applications<br>that will need to be written in the coming years will be <br>[server-based\<br>applications](https://paulgraham.com/road.html). There's no reason a new Lisp shouldn't have string<br>libraries as good as Perl, and if this new Lisp also had powerful<br>libraries for server-based applications, it could be very popular.<br>Real hackers won't turn up their noses at a new tool that will let<br>them solve hard problems with a few library calls. Remember, hackers<br>are lazy.<br>It could be an even bigger win to have core language support for<br>server-based applications. For example, explicit support for programs<br>with multiple users, or data ownership at the level of type tags.<br>Server-based applications also give us the answer to the question<br>of what this new Lisp will be used to hack. It would not hurt to<br>make Lisp better as a scripting language for Unix. (It would be<br>hard to make it worse.) But I think there are areas where existing<br>languages would be easier to beat. I think it might be better to<br>follow the model of Tcl, and supply the Lisp together with a complete<br>system for supporting server-based applications. Lisp is a natural<br>fit for server-based applications. Lexical closures provide a way<br>to get the effect of subroutines when the ui is just a series of<br>web pages. S-expressions map nicely onto html, and macros are good<br>at generating it. There need to be better tools for writing<br>server-based applications, and there needs to be a new Lisp, and<br>the two would work very well together.<br>**12 The Dream Language**<br>By way of summary, let's try describing the hacker's dream language.<br>The dream language is <br>[beautiful](https://paulgraham.com/taste.html), clean, and terse. It has an<br>interactive toplevel that starts up fast. You can write programs<br>to solve common problems with very little code. Nearly all the<br>code in any program you write is code that's specific to your<br>application. Everything else has been done for you.<br>The syntax of the language is brief to a fault. You never have to<br>type an unnecessary character, or even to use the shift key much.<br>Using big abstractions you can write the first version of a program<br>very quickly. Later, when you want to optimize, there's a really<br>good profiler that tells you where to focus your attention. You<br>can make inner loops blindingly fast, even writing inline byte code<br>if you need to.<br>There are lots of good examples to learn from, and the language is<br>intuitive enough that you can learn how to use it from examples in<br>a couple minutes. You don't need to look in the manual much. The<br>manual is thin, and has few warnings and qualifications.<br>The language has a small core, and powerful, highly orthogonal<br>libraries that are as carefully designed as the core language. The<br>libraries all work well together; everything in the language fits<br>together like the parts in a fine camera. Nothing is deprecated,<br>or retained for compatibility. The source code of all the libraries<br>is readily available. It's easy to talk to the operating system<br>and to applications written in other languages.<br>The language is built in layers. The higher-level abstractions are<br>built in a very transparent way out of lower-level abstractions,<br>which you can get hold of if you want.<br>Nothing is hidden from you that doesn't absolutely have to be. The<br>language offers abstractions only as a way of saving you work,<br>rather than as a way of telling you what to do. In fact, the language<br>encourages you to be an equal participant in its design. You can<br>change everything about it, including even its syntax, and anything<br>you write has, as much as possible, the same status as what comes<br>predefined.<br>**Notes**<br>\[1\] Macros very close to the modern idea were proposed by Timothy<br>Hart in 1964, two years after Lisp 1.5 was released. What was<br>missing, initially, were ways to avoid variable capture and multiple<br>evaluation; Hart's examples are subject to both.<br>\[2\] In _When the Air Hits Your Brain,_ neurosurgeon Frank Vertosick<br>recounts a conversation in which his chief resident, Gary, talks<br>about the difference between surgeons and internists ("fleas"):<br>> Gary and I ordered a large pizza and found an open booth. The<br>>  chief lit a cigarette. "Look at those goddamn fleas, jabbering<br>>  about some disease they'll see once in their lifetimes. That's<br>>  the trouble with fleas, they only like the bizarre stuff. They<br>>  hate their bread and butter cases. That's the difference between<br>>  us and the fucking fleas. See, we love big juicy lumbar disc<br>>  herniations, but they hate hypertension...."<br>It's hard to think of a lumbar disc herniation as juicy (except<br>literally). And yet I think I know what they mean. I've often had<br>a juicy bug to track down. Someone who's not a programmer would<br>find it hard to imagine that there could be pleasure in a bug.<br>Surely it's better if everything just works. In one way, it is.<br>And yet there is undeniably a grim satisfaction in hunting down<br>certain sorts of bugs. |

|     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://s.turbifycdn.com/aah/paulgraham/serious-2.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | [Postscript Version](https://sep.turbifycdn.com/ty/cdn/paulgraham/bepop.ps?t=1688221954&)<br>![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | ![](https://s.turbifycdn.com/aah/paulgraham/serious-2.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | [Arc](http://www.paulgraham.com/arc.html)<br>![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://s.turbifycdn.com/aah/paulgraham/serious-2.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | [Five Questions about Language Design](https://paulgraham.com/langdes.html)<br>![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | ![](https://s.turbifycdn.com/aah/paulgraham/serious-2.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | [How to Become a Hacker](http://www.catb.org/~esr/faqs/hacker-howto.html)<br>![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://s.turbifycdn.com/aah/paulgraham/serious-2.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | [Japanese Translation](http://www.shiro.dreamhost.com/scheme/trans/being-popular-j.html)<br>![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |

|     |
| --- |
| * * * | |
