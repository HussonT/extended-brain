# Aengus Lynch

## Connection to Me
- **CEO of WatertightAI** - the startup that I'm joining

## Professional Background

### Current Positions
- **PhD Student at University College London (UCL)**
  - Research focus: AI Alignment, mechanistic interpretability, and AI safety
  - Former MATS (Machine Learning Alignment) scholar with Stephen Casper
  - Contract researcher with Anthropic
  - Associated with Entrepreneurs First

### Location
- San Francisco, California, United States

## Research & Expertise

### Research Focus Areas
- AI alignment and safety
- Mechanistic interpretability
- Finding and fixing ways AI systems can fail
- Studying potential harmful behaviors in AI systems
- Agentic misalignment - demonstrating AI deception and blackmail potential

### Notable Publications & Research
- **Lead Author: "Agentic Misalignment"** - Featured in Claude 4 system card
- **"Best-of-N Jailbreaking"** (2024)
- **"Latent Adversarial Training Improves Robustness"** (2024)
- **"Towards Automated Circuit Discovery"** (2023) - NeurIPS Spotlight paper

### Media Coverage
His research on AI safety vulnerabilities has been featured in:
- BBC
- Fortune
- HuffPost
- VentureBeat
- Axios

## Education
- **UCL (University College London)** - 2017-2021
- Additional education: 2015-2017

## Professional Profiles
- **Website:** [aenguslynch.com](https://www.aenguslynch.com/)
- **Google Scholar:** Available
- **GitHub:** @aengusl
- **LinkedIn:** [Aengus Lynch](https://www.linkedin.com/in/aengus-lynch-2876a6125/)
- **Twitter:** @aengus_lynch1

## Background Notes
- Previously received a recommendation from Paul Robinson for internship work at Doctify
- Has over 1,000 followers on LinkedIn
- Known for identifying critical safety vulnerabilities in advanced AI systems
- His work focuses on the practical challenges of ensuring AI systems behave as intended

## Related to WatertightAI
*[Note: To be updated with more information about his role at WatertightAI as it becomes available]*

---
*Last updated: {{date}}*