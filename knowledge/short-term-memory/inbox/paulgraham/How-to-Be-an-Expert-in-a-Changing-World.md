---
title: "How to Be an Expert in a Changing World"
author: Paul Graham
source: http://paulgraham.com/ecw.html
year_published: Unknown
date_scraped: 2025-08-07
time_scraped: 14:08:54
word_count: 1020
scrape_method: firecrawl
tags: [paul-graham, essays]
---

# How to Be an Expert in a Changing World

|     |     |     |
| --- | --- | --- |
| ![](https://s.turbifycdn.com/aah/paulgraham/essays-5.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | [![](https://s.turbifycdn.com/aah/paulgraham/essays-6.gif)](https://paulgraham.com/index.html)

|     |
| --- |
| ![How to Be an Expert in a Changing World](https://s.turbifycdn.com/aah/paulgraham/how-to-be-an-expert-in-a-changing-world-4.gif)<br>December 2014<br>If the world were static, we could have monotonically increasing<br>confidence in our beliefs. The more (and more varied) experience<br>a belief survived, the less likely it would be false. Most people<br>implicitly believe something like this about their opinions. And<br>they're justified in doing so with opinions about things that don't<br>change much, like human nature. But you can't trust your opinions<br>in the same way about things that change, which could include<br>practically everything else.<br>When experts are wrong, it's often because they're experts on an<br>earlier version of the world.<br>Is it possible to avoid that? Can you protect yourself against<br>obsolete beliefs? To some extent, yes. I spent almost a decade<br>investing in early stage startups, and curiously enough protecting<br>yourself against obsolete beliefs is exactly what you have to do<br>to succeed as a startup investor. Most really good startup ideas<br>look like bad ideas at first, and many of those look bad specifically<br>because some change in the world just switched them from bad to<br>good. I spent a lot of time learning to recognize such ideas, and<br>the techniques I used may be applicable to ideas in general.<br>The first step is to have an explicit belief in change. People who<br>fall victim to a monotonically increasing confidence in their<br>opinions are implicitly concluding the world is static. If you<br>consciously remind yourself it isn't, you start to look for change.<br>Where should one look for it? Beyond the moderately useful<br>generalization that human nature doesn't change much, the unfortunate<br>fact is that change is hard to predict. This is largely a tautology<br>but worth remembering all the same: change that matters usually<br>comes from an unforeseen quarter.<br>So I don't even try to predict it. When I get asked in interviews<br>to predict the future, I always have to struggle to come up with<br>something plausible-sounding on the fly, like a student who hasn't<br>prepared for an exam.<br>\[ [1](https://paulgraham.com/ecw.html#f1n)\]<br>But it's not out of laziness that I haven't<br>prepared. It seems to me that beliefs about the future are so<br>rarely correct that they usually aren't worth the extra rigidity<br>they impose, and that the best strategy is simply to be aggressively<br>open-minded. Instead of trying to point yourself in the right<br>direction, admit you have no idea what the right direction is, and<br>try instead to be super sensitive to the winds of change.<br>It's ok to have working hypotheses, even though they may constrain<br>you a bit, because they also motivate you. It's exciting to chase<br>things and exciting to try to guess answers. But you have to be<br>disciplined about not letting your hypotheses harden into anything<br>more.<br>\[ [2](https://paulgraham.com/ecw.html#f2n)\]<br>I believe this passive m.o. works not just for evaluating new ideas<br>but also for having them. The way to come up with new ideas is not<br>to try explicitly to, but to try to solve problems and simply not<br>discount weird hunches you have in the process.<br>The winds of change originate in the unconscious minds of domain<br>experts. If you're sufficiently expert in a field, any weird idea<br>or apparently irrelevant question that occurs to you is ipso facto<br>worth exploring. <br>\[ [3](https://paulgraham.com/ecw.html#f3n)\]<br> Within Y Combinator, when an idea is described<br>as crazy, it's a compliment—in fact, on average probably a<br>higher compliment than when an idea is described as good.<br>Startup investors have extraordinary incentives for correcting<br>obsolete beliefs. If they can realize before other investors that<br>some apparently unpromising startup isn't, they can make a huge<br>amount of money. But the incentives are more than just financial.<br>Investors' opinions are explicitly tested: startups come to them<br>and they have to say yes or no, and then, fairly quickly, they learn<br>whether they guessed right. The investors who say no to a Google<br>(and there were several) will remember it for the rest of their<br>lives.<br>Anyone who must in some sense bet on ideas rather than merely<br>commenting on them has similar incentives. Which means anyone who<br>wants such incentives can have them, by turning their comments into<br>bets: if you write about a topic in some fairly durable and public<br>form, you'll find you worry much more about getting things right<br>than most people would in a casual conversation.<br>\[ [4](https://paulgraham.com/ecw.html#f4n)\]<br>Another trick I've found to protect myself against obsolete beliefs<br>is to focus initially on people rather than ideas. Though the nature<br>of future discoveries is hard to predict, I've found I can predict<br>quite well what sort of people will make them. Good new ideas come<br>from earnest, energetic, independent-minded people.<br>Betting on people over ideas saved me countless times as an investor.<br>We thought Airbnb was a bad idea, for example. But we could tell<br>the founders were earnest, energetic, and independent-minded.<br>(Indeed, almost pathologically so.) So we suspended disbelief and<br>funded them.<br>This too seems a technique that should be generally applicable.<br>Surround yourself with the sort of people new ideas come from. If<br>you want to notice quickly when your beliefs become obsolete, you<br>can't do better than to be friends with the people whose discoveries<br>will make them so.<br>It's hard enough already not to become the prisoner of your own<br>expertise, but it will only get harder, because change is accelerating.<br>That's not a recent trend; change has been accelerating since the<br>paleolithic era. Ideas beget ideas. I don't expect that to change.<br>But I could be wrong.<br>**Notes**<br>\[1\]<br>My usual trick is to talk about aspects of the present that<br>most people haven't noticed yet.<br>\[2\]<br>Especially if they become well enough known that people start<br>to identify them with you. You have to be extra skeptical about<br>things you want to believe, and once a hypothesis starts to be<br>identified with you, it will almost certainly start to be in that<br>category.<br>\[3\]<br>In practice "sufficiently expert" doesn't require one to be<br>recognized as an expert—which is a trailing indicator in any<br>case. In many fields a year of focused work plus caring a lot would<br>be enough.<br>\[4\]<br>Though they are public and persist indefinitely, comments on<br>e.g. forums and places like Twitter seem empirically to work like<br>casual conversation. The threshold may be whether what you write<br>has a title.<br>**Thanks** to Sam Altman, Patrick Collison, and Robert Morris<br>for reading drafts of this. |

|     |     |     |
| --- | --- | --- |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://s.turbifycdn.com/aah/paulgraham/how-to-get-new-ideas-5.gif)[Spanish Translation](http://nrike.svbtle.com/cmo-ser-un-experto-en-un-mundo-cambiante)![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) | ![](https://s.turbifycdn.com/aah/paulgraham/how-to-get-new-ideas-5.gif)[Arabic Translation](https://tldrarabiccontents.blogspot.com/2020/01/blog-post_31.html)![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |
| ![](https://sep.turbifycdn.com/ca/Img/trans_1x1.gif) |

|     |
| --- |
| * * * | |
